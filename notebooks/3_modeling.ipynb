{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Detection Modeling\n",
    "\n",
    "This notebook demonstrates how to use the rule-based, statistical, and ensemble anomaly detection models in our fraud detection system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('/Users/m1pro/Documents/GitHub/fraud_detection_system') # Adjust the path as necessary\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src.models.rule_based import RuleBasedAnomalyDetector\n",
    "from src.models.statistical import StatisticalAnomalyDetector\n",
    "from src.models.ensemble import EnsembleAnomalyDetector\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule-Based Anomaly Detection\n",
    "\n",
    "We'll start by using the rule-based anomaly detector which applies business rules and heuristics to flag unusual transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6da2aba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded feature_store.csv:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_log</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_id</th>\n",
       "      <th>transaction_type</th>\n",
       "      <th>amount</th>\n",
       "      <th>currency</th>\n",
       "      <th>location</th>\n",
       "      <th>device</th>\n",
       "      <th>is_parsed</th>\n",
       "      <th>parse_errors</th>\n",
       "      <th>...</th>\n",
       "      <th>type_rarity</th>\n",
       "      <th>location_device</th>\n",
       "      <th>location_device_frequency</th>\n",
       "      <th>location_device_rarity</th>\n",
       "      <th>hour_type</th>\n",
       "      <th>hour_type_frequency</th>\n",
       "      <th>hour_type_rarity</th>\n",
       "      <th>amount_percentile</th>\n",
       "      <th>amount_deviation_location</th>\n",
       "      <th>amount_deviation_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-06-01 12:03:31 - user=user1000 - action=c...</td>\n",
       "      <td>2025-06-01 12:03:31</td>\n",
       "      <td>user1000</td>\n",
       "      <td>cashout</td>\n",
       "      <td>2235.91</td>\n",
       "      <td>$</td>\n",
       "      <td>London</td>\n",
       "      <td>Samsung Galaxy S10</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000984</td>\n",
       "      <td>London_Samsung Galaxy S10</td>\n",
       "      <td>124</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>12_cashout</td>\n",
       "      <td>37</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.494340</td>\n",
       "      <td>32.055041</td>\n",
       "      <td>122.374640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/06/2025 19:19:50 ::: user1000 *** DEBIT :::...</td>\n",
       "      <td>2025-06-01 19:19:50</td>\n",
       "      <td>user1000</td>\n",
       "      <td>debit</td>\n",
       "      <td>1267.67</td>\n",
       "      <td>£</td>\n",
       "      <td>Manchester</td>\n",
       "      <td>Xiaomi Mi 11</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000992</td>\n",
       "      <td>Manchester_Xiaomi Mi 11</td>\n",
       "      <td>136</td>\n",
       "      <td>0.007299</td>\n",
       "      <td>19_debit</td>\n",
       "      <td>41</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.280293</td>\n",
       "      <td>1024.647175</td>\n",
       "      <td>1053.774806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-06-02 19:52:44 | user: user1000 | txn: re...</td>\n",
       "      <td>2025-06-02 19:52:44</td>\n",
       "      <td>user1000</td>\n",
       "      <td>refund</td>\n",
       "      <td>2708.01</td>\n",
       "      <td>$</td>\n",
       "      <td>Cardiff</td>\n",
       "      <td>Huawei P30</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001104</td>\n",
       "      <td>Cardiff_Huawei P30</td>\n",
       "      <td>113</td>\n",
       "      <td>0.008772</td>\n",
       "      <td>19_refund</td>\n",
       "      <td>38</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.601106</td>\n",
       "      <td>399.260344</td>\n",
       "      <td>288.250044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-06-03 10:11:53 - user=user1000 - action=c...</td>\n",
       "      <td>2025-06-03 10:11:53</td>\n",
       "      <td>user1000</td>\n",
       "      <td>cashout</td>\n",
       "      <td>4659.06</td>\n",
       "      <td>£</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>Nokia 3310</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000984</td>\n",
       "      <td>Birmingham_Nokia 3310</td>\n",
       "      <td>132</td>\n",
       "      <td>0.007519</td>\n",
       "      <td>10_cashout</td>\n",
       "      <td>45</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.961796</td>\n",
       "      <td>2371.998033</td>\n",
       "      <td>2300.775360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-06-03 21:23:30 | user: user1000 | txn: ca...</td>\n",
       "      <td>2025-06-03 21:23:30</td>\n",
       "      <td>user1000</td>\n",
       "      <td>cashout</td>\n",
       "      <td>4063.97</td>\n",
       "      <td>£</td>\n",
       "      <td>Liverpool</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000984</td>\n",
       "      <td>Liverpool_nan</td>\n",
       "      <td>138</td>\n",
       "      <td>0.007194</td>\n",
       "      <td>21_cashout</td>\n",
       "      <td>45</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.871495</td>\n",
       "      <td>1770.661188</td>\n",
       "      <td>1705.685360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             raw_log            timestamp  \\\n",
       "0  2025-06-01 12:03:31 - user=user1000 - action=c...  2025-06-01 12:03:31   \n",
       "1  01/06/2025 19:19:50 ::: user1000 *** DEBIT :::...  2025-06-01 19:19:50   \n",
       "2  2025-06-02 19:52:44 | user: user1000 | txn: re...  2025-06-02 19:52:44   \n",
       "3  2025-06-03 10:11:53 - user=user1000 - action=c...  2025-06-03 10:11:53   \n",
       "4  2025-06-03 21:23:30 | user: user1000 | txn: ca...  2025-06-03 21:23:30   \n",
       "\n",
       "    user_id transaction_type   amount currency    location  \\\n",
       "0  user1000          cashout  2235.91        $      London   \n",
       "1  user1000            debit  1267.67        £  Manchester   \n",
       "2  user1000           refund  2708.01        $     Cardiff   \n",
       "3  user1000          cashout  4659.06        £  Birmingham   \n",
       "4  user1000          cashout  4063.97        £   Liverpool   \n",
       "\n",
       "               device  is_parsed  parse_errors  ...  type_rarity  \\\n",
       "0  Samsung Galaxy S10       True           NaN  ...     0.000984   \n",
       "1        Xiaomi Mi 11       True           NaN  ...     0.000992   \n",
       "2          Huawei P30       True           NaN  ...     0.001104   \n",
       "3          Nokia 3310       True           NaN  ...     0.000984   \n",
       "4                 NaN       True           NaN  ...     0.000984   \n",
       "\n",
       "             location_device  location_device_frequency  \\\n",
       "0  London_Samsung Galaxy S10                        124   \n",
       "1    Manchester_Xiaomi Mi 11                        136   \n",
       "2         Cardiff_Huawei P30                        113   \n",
       "3      Birmingham_Nokia 3310                        132   \n",
       "4              Liverpool_nan                        138   \n",
       "\n",
       "   location_device_rarity   hour_type  hour_type_frequency hour_type_rarity  \\\n",
       "0                0.008000  12_cashout                   37         0.026316   \n",
       "1                0.007299    19_debit                   41         0.023810   \n",
       "2                0.008772   19_refund                   38         0.025641   \n",
       "3                0.007519  10_cashout                   45         0.021739   \n",
       "4                0.007194  21_cashout                   45         0.021739   \n",
       "\n",
       "   amount_percentile  amount_deviation_location amount_deviation_type  \n",
       "0           0.494340                  32.055041            122.374640  \n",
       "1           0.280293                1024.647175           1053.774806  \n",
       "2           0.601106                 399.260344            288.250044  \n",
       "3           0.961796                2371.998033           2300.775360  \n",
       "4           0.871495                1770.661188           1705.685360  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read the feature_store.csv as input data\n",
    "feature_store_path = \"../results/feature_store.csv\"\n",
    "feature_df = pd.read_csv(feature_store_path)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(\"Loaded feature_store.csv:\")\n",
    "display(feature_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c49ecc",
   "metadata": {},
   "source": [
    "### How the RuleBasedAnomalyDetector Works\n",
    " \n",
    "The `RuleBasedAnomalyDetector` is a fraud detection system that uses a set of predefined business rules and heuristics to identify potentially fraudulent transactions. Each rule is designed to capture a specific type of suspicious behavior listed below:\n",
    " - Large or unusual transaction amounts\n",
    " - Transactions at odd hours (e.g., late night)\n",
    " - High frequency of transactions in a short time\n",
    " - Rare or new locations/devices\n",
    " - Unusual transaction types for a user\n",
    " \n",
    "**Here's how it works:**\n",
    " \n",
    " - **Initialization:** When the detector is created, it loads a set of rules, each with its own logic, parameters, and weight (importance).\n",
    " - **Rule Evaluation:** For each transaction, every rule is applied. If a rule is triggered (i.e., the transaction matches the suspicious pattern), it contributes to the transaction's anomaly score.\n",
    " - **Scoring:** The anomaly score for a transaction is a weighted sum of the triggered rules. The higher the score, the more likely the transaction is considered anomalous or fraudulent.\n",
    " - **Thresholding:** Transactions with scores above a certain threshold are flagged as potential fraud.\n",
    " \n",
    "For every transaction, each rule is checked. If a rule is triggered, it contributes a weighted score.\n",
    "The final anomaly score is the sum of all triggered rule weights for that transaction.\n",
    "A higher total score means the transaction matches more suspicious patterns and is more likely to be flagged as anomalous.\n",
    "This approach is transparent and interpretable, making it easy to understand why a transaction was flagged. It is especially useful for incorporating domain knowledge and business logic into the fraud detection process.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.models.rule_based:Initialized 10 fraud detection rules\n",
      "INFO:src.models.rule_based:Rule-based anomaly detector initialized\n",
      "INFO:src.models.rule_based:Running rule-based anomaly detection on 7774 transactions...\n",
      "INFO:src.models.rule_based:Rule-based detection complete. Mean anomaly score: 0.1821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rule-Based Anomaly Scores: 0       0.142857\n",
      "1       0.142857\n",
      "2       0.142857\n",
      "3       0.314286\n",
      "4       0.142857\n",
      "          ...   \n",
      "7769    0.142857\n",
      "7770    0.142857\n",
      "7771    0.142857\n",
      "7772    0.114286\n",
      "7773    0.142857\n",
      "Name: amount, Length: 7774, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Initialize and run the rule-based detector\n",
    "rule_detector = RuleBasedAnomalyDetector()\n",
    "\n",
    "# Run anomaly detection\n",
    "rule_scores, rule_details = rule_detector.detect_anomalies(feature_df)\n",
    "\n",
    "# Display rule-based results\n",
    "print('Rule-Based Anomaly Scores:', rule_scores)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "facdb8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Rule-Based Anomaly Scores:\n",
      "    user_id  anomaly_score\n",
      "0  user1097       0.542857\n",
      "1  user1097       0.542857\n",
      "2  user1020       0.514286\n",
      "3  user1003       0.514286\n",
      "4  user1098       0.514286\n",
      "5  user1081       0.514286\n",
      "6  user1021       0.457143\n",
      "7  user1065       0.457143\n",
      "8  user1031       0.457143\n",
      "9  user1037       0.457143\n"
     ]
    }
   ],
   "source": [
    "# Display the top 10 rule-based anomaly scores\n",
    "\n",
    "\n",
    "# Create a DataFrame to display user and their anomaly score\n",
    "if hasattr(feature_df, 'user_id'):\n",
    "    user_col = 'user_id'\n",
    "elif 'user_id' in feature_df.columns:\n",
    "    user_col = 'user_id'\n",
    "else:\n",
    "    user_col = feature_df.columns[0]  # fallback\n",
    "\n",
    "top_n = 10\n",
    "rule_scores_df = pd.DataFrame({\n",
    "    'user_id': feature_df[user_col],\n",
    "    'anomaly_score': rule_scores\n",
    "})\n",
    "\n",
    "# Sort by anomaly score descending and display top 10\n",
    "top_rule_scores = rule_scores_df.sort_values('anomaly_score', ascending=False).head(top_n)\n",
    "print(\"Top 10 Rule-Based Anomaly Scores:\")\n",
    "print(top_rule_scores.reset_index(drop=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Anomaly Detection\n",
    "\n",
    "Next, we demonstrate using statistical models like Isolation Forest and DBSCAN to detect anomalies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd11745b",
   "metadata": {},
   "source": [
    "\n",
    "The `StatisticalAnomalyDetector` uses statistical machine learning models to identify unusual transactions based on patterns in the data. \n",
    "Typically, it leverages algorithms such as Isolation Forest and DBSCAN:\n",
    " \n",
    "- **Isolation Forest** works by randomly partitioning the data and isolating observations. Anomalies are more easily isolated and thus receive higher anomaly scores.\n",
    "- **DBSCAN** (Density-Based Spatial Clustering of Applications with Noise) groups together points that are closely packed and labels points that lie alone in low-density regions as anomalies.\n",
    " \n",
    "The detector is first fitted to the transaction feature data, learning the normal patterns. It then assigns an anomaly score to each transaction, where higher scores indicate a greater likelihood of being anomalous or fraudulent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.models.statistical:Initialized 5 statistical models\n",
      "INFO:src.models.statistical:Statistical anomaly detector initialized\n",
      "INFO:src.models.statistical:Fitting statistical models on 7774 samples...\n",
      "INFO:src.models.statistical:Preparing features for statistical models...\n",
      "INFO:src.models.statistical:Prepared 53 features for 7774 samples\n",
      "INFO:src.models.statistical:✅ Isolation Forest fitted\n",
      "INFO:src.models.statistical:✅ One-Class SVM fitted\n",
      "INFO:src.models.statistical:✅ Local Outlier Factor fitted\n",
      "INFO:src.models.statistical:Statistical models fitting complete. 3 models fitted.\n",
      "INFO:src.models.statistical:Predicting anomalies for 7774 samples...\n",
      "INFO:src.models.statistical:Preparing features for statistical models...\n",
      "INFO:src.models.statistical:Prepared 53 features for 7774 samples\n",
      "/Users/m1pro/Documents/GitHub/fraud_detection_system/venv/lib/python3.9/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/m1pro/Documents/GitHub/fraud_detection_system/venv/lib/python3.9/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "INFO:src.models.statistical:Statistical anomaly detection complete. Generated 5 score sets.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical Anomaly Scores: {'isolation_forest': array([0.12992247, 0.12444061, 0.23723035, ..., 0.36334529, 0.6232587 ,\n",
      "       0.49936178]), 'one_class_svm': array([0.2920501 , 0.18405193, 0.32209424, ..., 0.18803552, 0.40121102,\n",
      "       0.32655532]), 'lof': array([0.20341514, 0.15641548, 0.16825087, ..., 0.06699607, 0.25230028,\n",
      "       0.13222091]), 'dbscan': array([1., 1., 1., ..., 1., 1., 1.]), 'hdbscan': array([0.13194602, 0.0223217 , 0.19747059, ..., 0.04932377, 0.0623968 ,\n",
      "       0.28943835])}\n"
     ]
    }
   ],
   "source": [
    "# Initialize and fit the statistical detector\n",
    "statistical_detector = StatisticalAnomalyDetector()\n",
    "statistical_detector.fit(feature_df)\n",
    "\n",
    "# Predict anomalies\n",
    "stat_scores = statistical_detector.predict_anomalies(feature_df)\n",
    "\n",
    "# Display statistical results\n",
    "print('Statistical Anomaly Scores:', stat_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31aad71c",
   "metadata": {},
   "source": [
    "<!-- # \n",
    "# ### Interpreting StatisticalAnomalyDetector Output\n",
    "# \n",
    "# The output from the `StatisticalAnomalyDetector` is typically a set of anomaly scores—one for each transaction. These scores quantify how unusual or \"anomalous\" each transaction appears based on the statistical models used (e.g., Isolation Forest, One-Class SVM, Local Outlier Factor).\n",
    "# \n",
    "# **How to interpret the scores:**\n",
    "# - **Higher scores** indicate transactions that are more likely to be anomalous or fraudulent.\n",
    "# - **Lower scores** suggest transactions that are more typical or expected.\n",
    "# \n",
    "# The exact range and meaning of the scores can depend on the underlying model:\n",
    "# - For some models, scores may be negative (e.g., Isolation Forest), with lower values indicating higher anomaly.\n",
    "# - For others, scores may be probabilities or distances from the \"normal\" cluster.\n",
    "# \n",
    "# **Making sense of the output:**\n",
    "# - You can sort transactions by their anomaly score to identify the most suspicious ones.\n",
    "# - Investigate the top-scoring transactions to look for patterns or commonalities.\n",
    "# - Use a threshold (e.g., top 1% of scores) to flag transactions for further review.\n",
    "# \n",
    "# **Example:**\n",
    "# ```python\n",
    "# # Combine scores with transaction IDs for inspection\n",
    "# stat_scores_df = pd.DataFrame({\n",
    "#     'user_id': feature_df['user_id'],\n",
    "#     'anomaly_score': stat_scores\n",
    "# })\n",
    "# \n",
    "# # Show the top 10 most anomalous transactions\n",
    "# print(stat_scores_df.sort_values('anomaly_score', ascending=False).head(10))\n",
    "# ```\n",
    "# \n",
    "# By analyzing these results, you can prioritize which transactions to investigate for potential fraud.\n",
    " -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Anomaly Detection\n",
    "\n",
    "Finally, we'll run the ensemble anomaly detector that combines both rule-based and statistical approaches for more comprehensive detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.models.rule_based:Initialized 10 fraud detection rules\n",
      "INFO:src.models.rule_based:Rule-based anomaly detector initialized\n",
      "INFO:src.models.statistical:Initialized 5 statistical models\n",
      "INFO:src.models.statistical:Statistical anomaly detector initialized\n",
      "INFO:src.models.ensemble:Ensemble anomaly detector initialized\n",
      "INFO:src.models.ensemble:Fitting ensemble detector on 7774 samples...\n",
      "INFO:src.models.statistical:Fitting statistical models on 7774 samples...\n",
      "INFO:src.models.statistical:Preparing features for statistical models...\n",
      "INFO:src.models.statistical:Prepared 53 features for 7774 samples\n",
      "INFO:src.models.statistical:✅ Isolation Forest fitted\n",
      "INFO:src.models.statistical:✅ One-Class SVM fitted\n",
      "INFO:src.models.statistical:✅ Local Outlier Factor fitted\n",
      "INFO:src.models.statistical:Statistical models fitting complete. 3 models fitted.\n",
      "INFO:src.models.ensemble:✅ Rule-based detector ready\n",
      "INFO:src.models.ensemble:✅ Ensemble detector fitting complete\n",
      "INFO:src.models.ensemble:Running ensemble anomaly detection on 7774 samples...\n",
      "INFO:src.models.ensemble:🔍 Running rule-based detection...\n",
      "INFO:src.models.rule_based:Running rule-based anomaly detection on 7774 transactions...\n",
      "INFO:src.models.rule_based:Rule-based detection complete. Mean anomaly score: 0.1821\n",
      "INFO:src.models.ensemble:📊 Running statistical detection...\n",
      "INFO:src.models.statistical:Predicting anomalies for 7774 samples...\n",
      "INFO:src.models.statistical:Preparing features for statistical models...\n",
      "INFO:src.models.statistical:Prepared 53 features for 7774 samples\n",
      "/Users/m1pro/Documents/GitHub/fraud_detection_system/venv/lib/python3.9/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/m1pro/Documents/GitHub/fraud_detection_system/venv/lib/python3.9/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "INFO:src.models.statistical:Statistical anomaly detection complete. Generated 5 score sets.\n",
      "INFO:src.models.ensemble:🔗 Combining component scores...\n",
      "INFO:src.models.ensemble:Ensemble combination complete. Score range: [0.248, 0.722]\n",
      "INFO:src.models.ensemble:Ensemble detection complete. Mean score: 0.3727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "🚨 ENSEMBLE FRAUD DETECTION SYSTEM - COMPREHENSIVE REPORT\n",
      "====================================================================================================\n",
      "\n",
      "📊 OVERALL STATISTICS\n",
      "--------------------------------------------------\n",
      "📈 Total Transactions Analyzed: 7,774\n",
      "🎯 Mean Ensemble Score: 0.3727\n",
      "📏 Score Standard Deviation: 0.0635\n",
      "🔝 Highest Score: 0.7221\n",
      "🔻 Lowest Score: 0.2481\n",
      "\n",
      "⚠️ RISK LEVEL BREAKDOWN\n",
      "--------------------------------------------------\n",
      "🔥 CRITICAL RISK (>0.8): 0 transactions (0.0%)\n",
      "⚠️ HIGH RISK (0.7-0.8): 1 transactions (0.0%)\n",
      "⚡ MEDIUM RISK (0.5-0.7): 303 transactions (3.9%)\n",
      "📊 LOW RISK (0.3-0.5): 6,635 transactions (85.3%)\n",
      "✅ NORMAL (<0.3): 835 transactions (10.7%)\n",
      "\n",
      "👥 USERS BY RISK CATEGORY\n",
      "--------------------------------------------------\n",
      "\n",
      "⚠️ HIGH RISK USERS (1 unique users):\n",
      "   • user1026: Score 0.7221 (Max: 0.7221), 1 tx, £654 total, Unknown\n",
      "\n",
      "⚡ MEDIUM RISK USERS (79 unique users):\n",
      "   • user1080: Score 0.5964 (Max: 0.5964), 1 tx, £4759 total, Liverpool\n",
      "   • user1054: Score 0.5767 (Max: 0.5767), 1 tx, £4866 total, Unknown\n",
      "   • user1015: Score 0.5758 (Max: 0.6438), 7 tx, £14343 total, Cardiff\n",
      "   • user1020: Score 0.5718 (Max: 0.6958), 8 tx, £24427 total, Leeds\n",
      "   • user1049: Score 0.5700 (Max: 0.5792), 2 tx, £8904 total, Cardiff\n",
      "   ... and 74 more users\n",
      "\n",
      "🔍 COMPONENT ANALYSIS\n",
      "--------------------------------------------------\n",
      "📋 Rule-Based Detection:\n",
      "   • Mean Score: 0.1821\n",
      "   • Weight: 0.30\n",
      "   • High Risk (>0.7): 0 transactions\n",
      "\n",
      "📊 Statistical Detection:\n",
      "   • Isolation Forest: 0.3350 (High Risk: 213)\n",
      "   • One Class Svm: 0.3330 (High Risk: 67)\n",
      "   • Lof: 0.1374 (High Risk: 5)\n",
      "   • Dbscan: 1.0000 (High Risk: 7,774)\n",
      "   • Hdbscan: 0.1475 (High Risk: 4)\n",
      "\n",
      "👤 TOP ANOMALOUS USERS\n",
      "--------------------------------------------------\n",
      "Rank User         Max Ensemble Rule     Tx Count   Avg Amount   Total        Location     Type        \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1    user1026     0.7221       0.1830   32         2083.1       66658.9      Glasgow      withdrawal   ⚠️ HIGH\n",
      "2    user1020     0.6958       0.2064   238        2265.0       539079.9     Liverpool    cashout      ⚡ MEDIUM\n",
      "3    user1021     0.6764       0.1774   43         2370.4       101926.2     Manchester   cashout      ⚡ MEDIUM\n",
      "4    user1006     0.6623       0.1706   34         1813.1       61646.9      Leeds        transfer     ⚡ MEDIUM\n",
      "5    user1053     0.6506       0.1932   42         2257.1       94797.9      Glasgow      transfer     ⚡ MEDIUM\n",
      "6    user1001     0.6453       0.1845   35         1994.3       69799.0      Cardiff      transfer     ⚡ MEDIUM\n",
      "7    user1015     0.6438       0.1649   35         2014.7       70516.2      London       debit        ⚡ MEDIUM\n",
      "8    user1024     0.6257       0.1765   45         2123.8       95572.9      Manchester   purchase     ⚡ MEDIUM\n",
      "9    user1086     0.6188       0.1802   36         2238.8       80598.4      Glasgow      refund       ⚡ MEDIUM\n",
      "10   user1079     0.6116       0.1923   41         2529.5       103710.5     Cardiff      top-up       ⚡ MEDIUM\n",
      "\n",
      "🎯 ACTIONABLE INSIGHTS & RECOMMENDATIONS\n",
      "--------------------------------------------------\n",
      "\n",
      "⚠️ HIGH PRIORITY REVIEW:\n",
      "   • 1 transactions flagged as HIGH risk\n",
      "   • Recommend: MANUAL REVIEW required\n",
      "   • Consider additional verification for these users\n",
      "\n",
      "🔍 SUSPICIOUS PATTERNS DETECTED:\n",
      "   • 1 users have multiple high-risk transactions\n",
      "   • Top suspicious user: user1026 (1 high-risk tx)\n",
      "\n",
      "⚙️ SYSTEM PERFORMANCE:\n",
      "   • Ensemble model successfully processed 7,774 transactions\n",
      "   • Detection rate: 0.0% of transactions flagged\n",
      "   • Model confidence: MEDIUM\n",
      "\n",
      "📋 RECOMMENDED NEXT STEPS:\n",
      "   2. 👀 MANUAL REVIEW of high-risk transactions\n",
      "   3. 👤 INVESTIGATE top 5 suspicious users\n",
      "   4. 📊 MONITOR system performance and adjust thresholds if needed\n",
      "   5. 🔄 RETRAIN models with new data if detection rate is too high/low\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "💾 FRAUD REPORT EXPORTED: results/fraud_report_07-08-25-01:00.txt\n",
      "📄 Report contains comprehensive analysis of 7,774 transactions\n",
      "📊 DETAILED CSV EXPORTED: results/fraud_report_detailed_07-08-25-01:00.csv\n"
     ]
    }
   ],
   "source": [
    "# Initialize and fit the ensemble detector\n",
    "ensemble_detector = EnsembleAnomalyDetector()\n",
    "ensemble_detector.fit(feature_df)\n",
    "\n",
    "# Detect anomalies using the ensemble\n",
    "ensemble_scores, ensemble_results = ensemble_detector.detect_anomalies(feature_df)\n",
    "\n",
    "# Display ensemble results\n",
    "# print('Ensemble Anomaly Scores:', ensemble_scores)\n",
    "# print('Ensemble Results:', ensemble_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook illustrated the modeling process using rule-based, statistical, and ensemble methods to detect anomalies in transaction data, providing a comprehensive approach to fraud detection."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
